#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–Ω—è –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
    python3 merge_translation.py <chunks_dir> [--output output_file.yml] [--suffix fixed]

–ü—Ä–∏–∫–ª–∞–¥–∏:
    python3 merge_translation.py events_chunks
    python3 merge_translation.py chunks --output result.yml
    python3 merge_translation.py chunks --suffix translated
"""
import os
import sys
import glob
import json
import argparse
from pathlib import Path

def merge_chunks(chunks_dir, output_file=None, suffix='fixed'):
    """–û–±'—î–¥–Ω—É—î –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª"""

    print(f"üìÅ –®—É–∫–∞—é –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –≤: {chunks_dir}")

    # –ß–∏—Ç–∞—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ —è–∫—â–æ —î
    metadata_file = os.path.join(chunks_dir, 'metadata.json')
    metadata = None
    if os.path.exists(metadata_file):
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        print(f"üìñ –ó–Ω–∞–π–¥–µ–Ω–æ –º–µ—Ç–∞–¥–∞–Ω—ñ: {metadata_file}")

    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω—ñ —Ñ–∞–π–ª–∏
    pattern = os.path.join(chunks_dir, f'chunk_*_{suffix}.txt')
    translated_files = sorted(glob.glob(pattern))

    if not translated_files:
        print(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤ ({pattern})")
        print(f"   –ü–µ—Ä–µ–∫–ª–∞–¥–∏ —Å–ø–æ—á–∞—Ç–∫—É –≤—Å—ñ chunk_XXX.txt —Ç–∞ –∑–±–µ—Ä–µ–∂–∏ —è–∫ chunk_XXX_{suffix}.txt!")
        return False

    print(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ {len(translated_files)} –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω")

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –≤–∏—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª
    if output_file is None:
        if metadata and 'input_file' in metadata:
            output_file = metadata['input_file']
        else:
            # –ì–µ–Ω–µ—Ä—É—î–º–æ –Ω–∞–∑–≤—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–∞–ø–∫–∏
            base_name = Path(chunks_dir).stem.replace('_chunks', '')
            output_file = f"main_menu/localization/english/{base_name}_l_english.yml"

    print(f"üìù –í–∏—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª: {output_file}")

    # –û–±'—î–¥–Ω—É—î–º–æ
    all_lines = []
    header_added = False

    for i, translated_file in enumerate(translated_files, 1):
        print(f"üìñ [{i}/{len(translated_files)}] –ß–∏—Ç–∞—é: {os.path.basename(translated_file)}")

        with open(translated_file, 'r', encoding='utf-8-sig') as f:
            lines = f.readlines()

        # –ü–µ—Ä—à–∞ —á–∞—Å—Ç–∏–Ω–∞ –º–∞—î –∑–∞–≥–æ–ª–æ–≤–æ–∫
        if i == 1:
            all_lines.extend(lines)
            header_added = True
        else:
            # –Ü–Ω—à—ñ —á–∞—Å—Ç–∏–Ω–∏ - –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —è–∫—â–æ —î
            if lines and lines[0].strip().startswith('l_english:'):
                all_lines.extend(lines[1:])
            else:
                all_lines.extend(lines)

    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É —è–∫—â–æ –Ω–µ —ñ—Å–Ω—É—î
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    print(f"\n‚úçÔ∏è –ó–∞–ø–∏—Å—É—é –æ–±'—î–¥–Ω–∞–Ω–∏–π —Ñ–∞–π–ª...")
    with open(output_file, 'w', encoding='utf-8-sig') as f:
        f.writelines(all_lines)

    print(f"‚úÖ –ì–û–¢–û–í–û! –û–±'—î–¥–Ω–∞–Ω–æ {len(all_lines)} —Ä—è–¥–∫—ñ–≤")
    print(f"üìÑ –§–∞–π–ª –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_file}")

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–≤—ñ—Ç
    report_file = os.path.join(chunks_dir, 'merge_report.txt')
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("–ó–í–Ü–¢ –ü–†–û –û–ë'–Ñ–î–ù–ê–ù–ù–Ø\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"–î–∞—Ç–∞: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"–ü–∞–ø–∫–∞ –∑ —á–∞—Å—Ç–∏–Ω–∞–º–∏: {chunks_dir}\n")
        f.write(f"–í–∏—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª: {output_file}\n")
        f.write(f"–û–±'—î–¥–Ω–∞–Ω–æ —á–∞—Å—Ç–∏–Ω: {len(translated_files)}\n")
        f.write(f"–í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤: {len(all_lines)}\n\n")
        f.write("–ü–µ—Ä–µ–∫–ª–∞–¥–µ–Ω—ñ —Ñ–∞–π–ª–∏:\n")
        for tf in translated_files:
            f.write(f"  - {os.path.basename(tf)}\n")

    print(f"üìã –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {report_file}")

    return True

def main():
    parser = argparse.ArgumentParser(
        description='–û–±\'—î–¥–Ω–∞—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
–ü—Ä–∏–∫–ª–∞–¥–∏:
  %(prog)s events_chunks
  %(prog)s chunks --output result.yml
  %(prog)s chunks --suffix translated
        '''
    )

    parser.add_argument('chunks_dir', help='–ü–∞–ø–∫–∞ –∑ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏–º–∏ —á–∞—Å—Ç–∏–Ω–∞–º–∏')
    parser.add_argument('--output', help='–í–∏—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ metadata.json –∞–±–æ –≥–µ–Ω–µ—Ä—É—î—Ç—å—Å—è)')
    parser.add_argument('--suffix', default='fixed', help='–°—É—Ñ—ñ–∫—Å –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: fixed)')

    args = parser.parse_args()

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è –ø–∞–ø–∫–∏
    if not os.path.exists(args.chunks_dir):
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –ü–∞–ø–∫–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞: {args.chunks_dir}")
        sys.exit(1)

    success = merge_chunks(args.chunks_dir, output_file=args.output, suffix=args.suffix)

    if success:
        print("\n" + "=" * 80)
        print("üéâ –£–°–ü–Ü–®–ù–û –û–ë'–Ñ–î–ù–ê–ù–û!")
        print("=" * 80)
        print("\n–¢–µ–ø–µ—Ä –º–æ–∂–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–∞ –∑–∞–∫–æ–º—ñ—Ç–∏—Ç–∏ –∑–º—ñ–Ω–∏:")
        print("  git add <output_file>")
        print("  git commit -m '–ü–µ—Ä–µ–∫–ª–∞–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ'")
        print("  git push")
    else:
        print("\n" + "=" * 80)
        print("‚ùå –ü–û–ú–ò–õ–ö–ê!")
        print("=" * 80)
        sys.exit(1)

if __name__ == '__main__':
    main()
