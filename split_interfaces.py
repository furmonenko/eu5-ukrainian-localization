#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è interfaces_l_english.yml –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
"""
import os
import math

def count_tokens_approx(text):
    """–ü—Ä–∏–±–ª–∏–∑–Ω–∏–π –ø—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ —Ç–æ–∫–µ–Ω—ñ–≤ (1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∏ –¥–ª—è –∫–∏—Ä–∏–ª–∏—Ü—ñ)"""
    return len(text) // 3

def split_file(input_file, max_tokens=30000, output_dir='interfaces_chunks'):
    """–†–æ–∑–¥—ñ–ª—è—î —Ñ–∞–π–ª –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏"""

    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É –¥–ª—è —á–∞—Å—Ç–∏–Ω
    os.makedirs(output_dir, exist_ok=True)

    print(f"üìñ –ß–∏—Ç–∞—é —Ñ–∞–π–ª: {input_file}")
    with open(input_file, 'r', encoding='utf-8-sig') as f:
        lines = f.readlines()

    print(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ {len(lines)} —Ä—è–¥–∫—ñ–≤")

    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
    chunks = []
    current_chunk = []
    current_tokens = 0
    chunk_num = 1

    # –î–æ–¥–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ –ø–µ—Ä—à–æ—ó —á–∞—Å—Ç–∏–Ω–∏
    header = lines[0]

    for i, line in enumerate(lines[1:], 1):  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
        line_tokens = count_tokens_approx(line)

        if current_tokens + line_tokens > max_tokens and current_chunk:
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω—É —á–∞—Å—Ç–∏–Ω—É
            chunk_file = os.path.join(output_dir, f'chunk_{chunk_num:03d}.txt')

            # –ü–µ—Ä—à–∞ —á–∞—Å—Ç–∏–Ω–∞ –º–∞—î –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if chunk_num == 1:
                chunk_content = header + ''.join(current_chunk)
            else:
                chunk_content = ''.join(current_chunk)

            with open(chunk_file, 'w', encoding='utf-8-sig') as f:
                f.write(chunk_content)

            chunks.append({
                'num': chunk_num,
                'file': chunk_file,
                'lines': len(current_chunk),
                'tokens': current_tokens
            })

            print(f"‚úÖ –ß–∞—Å—Ç–∏–Ω–∞ {chunk_num}: {len(current_chunk)} —Ä—è–¥–∫—ñ–≤, ~{current_tokens} —Ç–æ–∫–µ–Ω—ñ–≤")

            # –ü–æ—á–∏–Ω–∞—î–º–æ –Ω–æ–≤—É —á–∞—Å—Ç–∏–Ω—É
            chunk_num += 1
            current_chunk = []
            current_tokens = 0

        current_chunk.append(line)
        current_tokens += line_tokens

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—é —á–∞—Å—Ç–∏–Ω—É
    if current_chunk:
        chunk_file = os.path.join(output_dir, f'chunk_{chunk_num:03d}.txt')

        if chunk_num == 1:
            chunk_content = header + ''.join(current_chunk)
        else:
            chunk_content = ''.join(current_chunk)

        with open(chunk_file, 'w', encoding='utf-8-sig') as f:
            f.write(chunk_content)

        chunks.append({
            'num': chunk_num,
            'file': chunk_file,
            'lines': len(current_chunk),
            'tokens': current_tokens
        })

        print(f"‚úÖ –ß–∞—Å—Ç–∏–Ω–∞ {chunk_num}: {len(current_chunk)} —Ä—è–¥–∫—ñ–≤, ~{current_tokens} —Ç–æ–∫en—ñ–≤")

    print(f"\nüéâ –†–æ–∑–¥—ñ–ª–µ–Ω–æ –Ω–∞ {len(chunks)} —á–∞—Å—Ç–∏–Ω!")
    print(f"üìÅ –ß–∞—Å—Ç–∏–Ω–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –≤: {output_dir}/")

    return chunks

def main():
    input_file = '/home/user/eu5-ukrainian-localization/main_menu/localization/english/interfaces_l_english.yml'
    output_dir = '/home/user/eu5-ukrainian-localization/interfaces_chunks'

    chunks = split_file(input_file, max_tokens=15000, output_dir=output_dir)

    print("\n" + "=" * 80)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("=" * 80)
    print(f"\n–†–æ–∑–¥—ñ–ª–µ–Ω–æ –Ω–∞ {len(chunks)} —á–∞—Å—Ç–∏–Ω.")
    print(f"–ß–∞—Å—Ç–∏–Ω–∏ –∑–Ω–∞—Ö–æ–¥—è—Ç—å—Å—è –≤ –ø–∞–ø—Ü—ñ: {output_dir}/")

if __name__ == '__main__':
    main()
